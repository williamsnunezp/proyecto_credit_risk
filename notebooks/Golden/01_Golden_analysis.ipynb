{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a32f8ca9-25df-46a1-9643-7c05e16d71b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Gold — Agregación y KPIs\n",
    "\n",
    "Propósito: Generar tablas agregadas, KPIs y vistas Golden listas para consumo analítico y BI.\n",
    "\n",
    "Rol: capa final de preparación — consolida métricas y tablas optimizadas para consumo, reporting y modelos de negocio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d271f25-cfe7-4da6-a8e9-7a632d633f11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import current_timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "784a1120-5efd-4230-b0c0-44f5e8416ccc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Leer la tabla Silver\n",
    "df_silver = spark.read.table(\"workspace.credit_risk.silver_credit_risk_limpio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ae0a542-0a41-4290-aa4f-47dddfdb65ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Creamos la data limpia sin outliers\n",
    "df_gold1 = (\n",
    "    df_silver\n",
    "    .filter(\"es_outlier = 0\")\n",
    "    .withColumn(\"fecha_procesamiento_tabla\", current_timestamp())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1d689b5-e73a-47ba-b066-2b8535eb8647",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Creamos la data con outliers\n",
    "df_gold2 = (\n",
    "    df_silver\n",
    "    .filter(\"es_outlier = 1\")\n",
    "    .withColumn(\"fecha_procesamiento_tabla\", current_timestamp())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf7b68dc-0b70-4d03-85b5-782c8bd0aac4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Calcular los KPIs usando agregaciones de PySpark\n",
    "df_gold_kpis = df_silver.select(\n",
    "    # Conteos básicos\n",
    "    F.count(\"*\").alias(\"total_prestamos\"),\n",
    "    F.count_distinct(\"id_cliente\").alias(\"total_clientes\"),\n",
    "    \n",
    "    # Métricas de montos\n",
    "    F.round(F.sum(\"monto\"), 2).alias(\"cartera_total\"),\n",
    "    F.round(F.avg(\"monto\"), 2).alias(\"monto_promedio\"),\n",
    "    F.round(F.max(\"monto\"), 2).alias(\"monto_maximo\"),\n",
    "    F.round(F.min(\"monto\"), 2).alias(\"monto_minimo\"),\n",
    "    \n",
    "    # Métricas de tasas\n",
    "    F.round(F.avg(\"tasa_interes\"), 2).alias(\"tasa_promedio\"),\n",
    "    F.round(F.max(\"tasa_interes\"), 2).alias(\"tasa_maxima\"),\n",
    "    F.round(F.min(\"tasa_interes\"), 2).alias(\"tasa_minima\"),\n",
    "    \n",
    "    # Métricas de riesgo (Equivalente a los CASE WHEN de SQL)\n",
    "    F.sum(F.when(F.col(\"estado_pago\") == 1, 1).otherwise(0)).alias(\"total_defaults\"),\n",
    "    F.sum(F.when(F.col(\"estado_pago\") == 0, 1).otherwise(0)).alias(\"total_al_dia\"),\n",
    "    F.round(F.avg(F.when(F.col(\"estado_pago\") == 1, 100.0).otherwise(0.0)), 2).alias(\"tasa_default_pct\"),\n",
    "    \n",
    "    # Métricas de clientes\n",
    "    F.round(F.avg(\"edad\"), 1).alias(\"edad_promedio\"),\n",
    "    F.round(F.avg(\"ingreso_anual\"), 2).alias(\"ingreso_promedio\"),\n",
    "    F.round(F.avg(\"anios_empleo\"), 1).alias(\"anios_empleo_promedio\"),\n",
    "    \n",
    "    # Ingresos estimados\n",
    "    F.round(F.sum(F.col(\"monto\") * F.col(\"tasa_interes\") / 100), 2).alias(\"ingresos_intereses_estimado\"),\n",
    "    \n",
    "    # Timestamp de auditoría\n",
    "    F.current_timestamp().alias(\"fecha_actualizacion\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59ccc0df-cdab-49be-8be8-a6e4d1b993c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 4. RESUMEN POR CALIFICACIÓN\n",
    "df_gold_resumen_calificacion = spark.sql(\"\"\"\n",
    "                                         \n",
    "CREATE OR REPLACE TABLE workspace.credit_risk.gold_resumen_calificacion AS\n",
    "SELECT \n",
    "    calificacion,\n",
    "    \n",
    "    -- Volumen\n",
    "    COUNT(*) as cantidad_prestamos,\n",
    "    ROUND(SUM(monto), 2) as monto_total,\n",
    "    ROUND(AVG(monto), 2) as monto_promedio,\n",
    "    \n",
    "    -- Participación\n",
    "    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as participacion_cantidad_pct,\n",
    "    ROUND(SUM(monto) * 100.0 / SUM(SUM(monto)) OVER(), 2) as participacion_monto_pct,\n",
    "    \n",
    "    -- Tasas\n",
    "    ROUND(AVG(tasa_interes), 2) as tasa_promedio,\n",
    "    ROUND(MIN(tasa_interes), 2) as tasa_minima,\n",
    "    ROUND(MAX(tasa_interes), 2) as tasa_maxima,\n",
    "    \n",
    "    -- Riesgo\n",
    "    SUM(CASE WHEN estado_pago = 1 THEN 1 ELSE 0 END) as cantidad_defaults,\n",
    "    ROUND(AVG(CASE WHEN estado_pago = 1 THEN 100.0 ELSE 0.0 END), 2) as tasa_default_pct,\n",
    "    \n",
    "    -- Perfil cliente\n",
    "    ROUND(AVG(edad), 1) as edad_promedio,\n",
    "    ROUND(AVG(ingreso_anual), 0) as ingreso_promedio,\n",
    "    \n",
    "    -- Ingresos\n",
    "    ROUND(SUM(monto * tasa_interes / 100), 2) as ingresos_intereses,\n",
    "    \n",
    "    CURRENT_TIMESTAMP() as fecha_actualizacion\n",
    "    \n",
    "FROM workspace.credit_risk.golden_credit_risk_sin_outliers\n",
    "GROUP BY calificacion\n",
    "ORDER BY calificacion;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec1b0b38-e4de-4ece-86a7-bce898da5829",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. RESUMEN POR PROPÓSITO\n",
    "df_gold_resumen_proposito = spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE workspace.credit_risk.gold_resumen_proposito AS\n",
    "SELECT \n",
    "    proposito,\n",
    "    -- Volumen\n",
    "    COUNT(*) as cantidad_prestamos,\n",
    "    ROUND(SUM(monto), 2) as monto_total,\n",
    "    ROUND(AVG(monto), 2) as monto_promedio,\n",
    "    \n",
    "    -- Participación en cartera\n",
    "    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as participacion_pct,\n",
    "    \n",
    "    -- Pricing\n",
    "    ROUND(AVG(tasa_interes), 2) as tasa_promedio,\n",
    "    \n",
    "    -- Riesgo\n",
    "    SUM(CASE WHEN estado_pago = 1 THEN 1 ELSE 0 END) as cantidad_defaults,\n",
    "    ROUND(AVG(CASE WHEN estado_pago = 1 THEN 100.0 ELSE 0.0 END), 2) as tasa_default_pct,\n",
    "    \n",
    "    -- Calificaciones predominantes\n",
    "    COUNT(CASE WHEN calificacion IN ('A','B','C') THEN 1 END) as prestamos_calidad_alta,\n",
    "    COUNT(CASE WHEN calificacion IN ('D','E') THEN 1 END) as prestamos_calidad_media,\n",
    "    COUNT(CASE WHEN calificacion IN ('F','G') THEN 1 END) as prestamos_calidad_baja,\n",
    "    \n",
    "    -- Perfil\n",
    "    ROUND(AVG(ingreso_anual), 0) as ingreso_promedio,\n",
    "    ROUND(AVG(edad), 1) as edad_promedio,\n",
    "    \n",
    "    -- Ranking\n",
    "    RANK() OVER (ORDER BY SUM(monto) DESC) as ranking_volumen,\n",
    "    \n",
    "    CURRENT_TIMESTAMP() as fecha_actualizacion\n",
    "    \n",
    "FROM workspace.credit_risk.golden_credit_risk_sin_outliers\n",
    "GROUP BY proposito\n",
    "ORDER BY monto_total DESC;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e5ce3d4-5e5b-4d9e-8074-726177c7741a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6. ANÁLISIS RIESGO POR SEGMENTO\n",
    "df_gold_analisis_riesgo = spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE workspace.credit_risk.gold_analisis_riesgo AS\n",
    "SELECT \n",
    "    calificacion,\n",
    "    \n",
    "    -- Segmentación por tipo vivienda\n",
    "    tipo_vivienda,\n",
    "    \n",
    "    -- Volumen\n",
    "    COUNT(*) as cantidad_prestamos,\n",
    "    ROUND(SUM(monto), 2) as exposicion_total,\n",
    "    ROUND(AVG(monto), 2) as monto_promedio,\n",
    "    \n",
    "    -- Tasas\n",
    "    ROUND(AVG(tasa_interes), 2) as tasa_promedio,\n",
    "    \n",
    "    -- Riesgo detallado\n",
    "    SUM(CASE WHEN estado_pago = 1 THEN 1 ELSE 0 END) as defaults,\n",
    "    SUM(CASE WHEN estado_pago = 0 THEN 1 ELSE 0 END) as al_dia,\n",
    "    ROUND(AVG(CASE WHEN estado_pago = 1 THEN 100.0 ELSE 0.0 END), 2) as tasa_default_pct,\n",
    "    \n",
    "    -- Monto en riesgo\n",
    "    ROUND(SUM(CASE WHEN estado_pago = 1 THEN monto ELSE 0 END), 2) as monto_en_default,\n",
    "    \n",
    "    -- Perfil del segmento\n",
    "    ROUND(AVG(ingreso_anual), 0) as ingreso_promedio,\n",
    "    ROUND(AVG(edad), 1) as edad_promedio,\n",
    "    ROUND(AVG(pct_ingreso * 100), 2) as pct_ingreso_comprometido,\n",
    "    \n",
    "    -- Categorización simple\n",
    "    CASE \n",
    "        WHEN AVG(CASE WHEN estado_pago = 1 THEN 1.0 ELSE 0.0 END) < 0.10 THEN 'RIESGO BAJO'\n",
    "        WHEN AVG(CASE WHEN estado_pago = 1 THEN 1.0 ELSE 0.0 END) < 0.20 THEN 'RIESGO MEDIO'\n",
    "        ELSE 'RIESGO ALTO'\n",
    "    END as categoria_riesgo,\n",
    "    \n",
    "    -- Ingresos\n",
    "    ROUND(SUM(monto * tasa_interes / 100), 2) as ingresos_estimados,\n",
    "    \n",
    "    CURRENT_TIMESTAMP() as fecha_actualizacion\n",
    "    \n",
    "FROM workspace.credit_risk.golden_credit_risk_sin_outliers\n",
    "GROUP BY calificacion, tipo_vivienda\n",
    "ORDER BY exposicion_total DESC;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dde8d865-b2f3-492c-8487-0b5b9ab0eafe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Guardar las tablas\n",
    "    df_gold1.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(\"workspace.credit_risk.golden_sin_outliers\")\n",
    "\n",
    "    df_gold2.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(\"workspace.credit_risk.golden_solo_outliers\")\n",
    "\n",
    "    df_gold_kpis.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(\"workspace.credit_risk.golden_kpis_basic\")\n",
    "\n",
    "    df_gold_resumen_calificacion.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(\"workspace.credit_risk.golden_resumen_calificacion\")\n",
    "\n",
    "    df_gold_resumen_proposito.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(\"workspace.credit_risk.golden_resumen_proposito\")\n",
    "\n",
    "    df_gold_analisis_riesgo.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(\"workspace.credit_risk.golden_analisis_riesgo\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Tipo de error\n",
    "    error_type = type(e).__name__\n",
    "    # Descripcion de error\n",
    "    error_summary = str(e)\n",
    "    # Trazar el error\n",
    "    error_trace = traceback.format_exc()\n",
    "\n",
    "    # Error completo\n",
    "    error_msg_full = \"f{error_type}: {error_sumamary}/n{error_trace}\"\n",
    "\n",
    "    if len(error_msg_full) > 500:\n",
    "        error_msg = error_msg_full[:500] + \"\\n[...]Error Truncado[...]\"\n",
    "    else:\n",
    "        error_msg = error_msg_full\n",
    "\n",
    "    dbutils.jobs.taskValues.set(key=\"error\", value=error_msg)\n",
    "    raise e\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6595204092972116,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Golden_analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
